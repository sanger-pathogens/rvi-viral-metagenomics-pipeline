// Config inheritance options
params {
    generic_config_base = "https://raw.githubusercontent.com/sanger-pathogens/nextflow-commons/"
    generic_config_version = "master"
    generic_config_url = ""
}
inherit_generic_config()

manifest {
    name            = 'rvi-pipeline'
    author          = 'PAM Informatics'
    homePage        = 'https://gitlab.internal.sanger.ac.uk/sanger-pathogens/pipelines/rvi-pipeline'
    description     = 'Meta-pipeline for RVI project data analysis including all steps of shotgun metagenomic sample processing'
    mainScript      = 'main.nf'
    nextflowVersion = '>=21.04.0'
    version         = '1.1.0'
}

//import IRODS_EXTRACTOR default config
includeConfig "./assorted-sub-workflows/irods_extractor/subworkflows/irods.config"
includeConfig "./modules/subsample/subsample.config"

params {
    // RVI pipeline specific parameters 
    outdir = "./results"
    help_all = false
    off_target_db = "/data/pam/software/RVI_DB/homo_sapiens"
    sequencer_source = "NexteraPE"
    trimmomatic_options = "ILLUMINACLIP:/data/pam/software/trimmomatic/adapter_fasta/solexa-with-nextseqPR-adapters.fasta:2:10:7:1 CROP:151 SLIDINGWINDOW:4:20 MINLEN:100"
    kneaddata_threads = 4
    metaspades_base_mem_gb = 16
    publish_raw_reads = false
    publish_trimmed_reads = true

    // abundance estimation params
    skip_qc_abundance_estimation = true
    genome_dir_abundance_estimation = "/data/pam/team162/shared/gtdb_genomes_reps_r207/gtdb_genomes_reps_r207_genome_dir"
    sourmash_db_abundance_estimation = "/data/pam/team162/shared/sourmash_db/gtdb-rs207.genomic-reps.dna.k31.zip"
    bowtie2_samtools_threads_abundance_estimation = 4
    instrain_threads_abundance_estimation = 4
    instrain_full_output_abundance_estimation = false
    instrain_quick_profile_abundance_estimation = false
    cleanup_intermediate_files_abundance_estimation = true
    instrain_quick_profile_abundance_estimation = false
    bowtie2_samtools_only_abundance_estimation = false
    bmtagger_db_abundance_estimation = "/data/pam/software/BMTAGGER_INDEX"
    bmtagger_host_abundance_estimation = "T2T-CHM13v2.0"
    publish_host_reads_abundance_estimation = false
    sourmash_subset_abundance_estimation = false
    genome_file_abundance_estimation = "/data/pam/software/RVI_DB/viral.1.1.genomic_sorted.fna"
    precomputed_index_abundance_estimation = "/data/pam/software/RVI_DB/viral.1.1.genomic_sorted.bt2"
    stb_file_abundance_estimation = "/data/pam/software/RVI_DB/viral.1.1.genomic.stb"

    // kraken2bracken params
    kraken2bracken_kraken2_db = "/data/pam/software/kraken2/viral_kraken/"
    kraken2bracken_kraken2_threads = 4
    kraken2bracken_bracken_threads = 10
    kraken2bracken_kmer_len = 35  // default provided bracken2 
    kraken2bracken_read_len = 150  // ideal length of reads in sample
    kraken2bracken_classification_level = 'S'  // [Options = 'D','P','C','O','F','G','S'] - taxonomic rank to analyze for bracken2
    kraken2bracken_threshold = 1  // minimum number of reads required for a classification at the specified rank
    kraken2bracken_get_classified_reads = false

    // LSF options
    queue_size = 50
    submit_rate_limit = '50/2min'

    // override IRODS_EXTRACTOR default
    preexisting_fastq_tag = "trimmed_reads"
    split_sep_for_ID_from_fastq = "_1_kneaddata_paired_1.fastq"
    cleanup_intermediate_files_irods_extractor = false
}

process {
    withName:KRAKEN2 {
        cpus = { params.kraken2bracken_kraken2_threads }
        memory = { estimate_kraken_mem(params.kraken2bracken_kraken2_db, 1, task) }
    }
}

// Helper functions
def inherit_generic_config() {
    config_url = params.generic_config_url ? params.generic_config_url : "${params.generic_config_base}/${params.generic_config_version}/configs/nextflow.config"
    try {
        includeConfig "${config_url}"
    } catch (Exception e) {
        System.err.println("ERROR: Could not load generic config: ${config_url}")
        System.err.println("Encountered the following exception:")
        throw e
    }
}

/*
Estimates required memory from kraken2 database files, accepts a memory top_up (in GB) to provide head room.
top_up will be increased linearly with each task attempt up to params.max_memory
*/
def estimate_kraken_mem(db, top_up, task) {
    float attempt = task.attempt
    float top_up_float = top_up
    def mem_file = new File("${db}/hash.k2d").size()
    def mem_top_up = (top_up_float * 1024**3) * attempt
    def mem_bytes = mem_file + mem_top_up
    def mem_mb = mem_bytes / (1024**2)
    def valid_mem = "${mem_mb.round()}.MB"
    if (valid_mem.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1) {
        return params.max_memory as nextflow.util.MemoryUnit
    }
    return valid_mem
}
